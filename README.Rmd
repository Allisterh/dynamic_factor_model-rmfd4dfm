---
title: 'Estimation of Impulse-Response Functions with Dynamic Factor Models: A New Parametrization'
output: 
  github_document:
    pandoc_args: --webtex
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

This repository contains the associated R-package and data to the paper [
Estimation of Impulse-Response Functions with Dynamic Factor Models: A New Parametrization
](https://arxiv.org/pdf/2202.00310) authored by Juho Koistinen and [Bernd Funovits](https://sites.google.com/site/berndfunovits/) (2022).
Specifically, the functions within the package allow the user to estimate
the structural dynamic factor model, where with the common component parametrized as the right matrix fraction 
description in echelon form (RMFD-E), which is introduced in [Section 2.2](https://arxiv.org/pdf/2202.00310.pdf#subsection.2.2)
of the associated paper. This document also shows how to replicate the empirical exercise of 
[Section 5](https://arxiv.org/pdf/2202.00310.pdf#section.5).

The package builds on the R-packages **rationalmatrices** and **RLDM**, authored by Bernd Funovits and Wolfgang Scherrer.
Since these packages might change, the parts which are necessary for the analysis in the associated article are extracted to R files **~/rmfd4dfm/R/zz_ratmat** and **~/rmfd4dfm/R/zz_rldm**. Importantly, please reference the **rationalmatrices** and the **RLDM** packages should you use their functionalities and not this package.

## Installation

The package can be installed using the following command as is the standard with
packages hosted by GitHub.

``` r
# install.packages("devtools")
devtools::install_github("juhokalle/rmfd4dfm")
```

## The Model and Argument

Here I will provide a brief and hopefully accessible introduction to the modelling approach presented in the paper, while the details are available from the paper.
The aim is to identify and estimate impulse-response functions (IRFs) using dynamic factor models (DFMs), with the emphasis placed on macroeconomic applications and and analysis.
The model of interest is given as 
$$
x_{t} =d_{0}z_{t}^{*}+d_{1}z_{t-1}^{*}+\cdots+d_{s}z_{t-s}^{*}+\xi_{t}\\
z_{t}^{*} =c_{1}z_{t-1}^{*}+\cdots+c_{p}z_{t-p}^{*}+\varepsilon_{t}, \\
\varepsilon_{t}=Hu_{t},
$$
where

* $x_t$ is an $n$-dimensional observed time series, with usually $n>100$.

* $z_t^*$ is a $q$-dimensional dynamic factor process, with usually $q<10$.

* $xi_t$ is an $n$-dimensional idiosyncratic term, we assume $\mathbb E(\xi_t \xi_t')=\sigma_\xi^2I_n$.

* $\varepsilon_t$ is the innovation to $z_t^*$, with $\mathbb E(\varepsilon_t \varepsilon_t')=\Sigma_\varepsilon$.

* $d_i$ and $c_j$, $i=0,\ldots,s$ $j=1,\ldots,p$, are $n \times q$ and $q \times q$ parameter matrices, values of which are at the center of interest as the IRFs are constructed from these matrices.

* $u_t$ is the $q$-dimensional structural shock process, with $\mathbb E (u_t u_t') = I_q$.

* $H$ is $(q\times q)$-dimensional structural shock impact matrix, which we identify as $H=chol(\Sigma_\varepsilon)$, where $chol(\Sigma_\varepsilon)$ is the lower triangular Cholesky factor of $\Sigma_\varepsilon$. Note that any other identification method for uncovering $H$ is valid as in the structural vector autoregression (SVAR) analysis.

We can write the dynamic factor process compactly as $z_t^*=c(L)^{-1}\varepsilon_t$ and substitute this and the equation for the innovations $\varepsilon_t$ into the equation for the observations to get $x_t=d(L)c(L)^{-1}H u_t + \xi_t$. If we assume that the idiosyncratic component accounts for measurements errors or sectoral dynamics that pertain to a small number of variables, we can use the structural IRF $k(L)H$ to study the shock propagation from $q$ structural shocks to $n$ observed macroeconomic variables, with $k(L)=d(L)c(L)^{-1}$. The IRF $k(L)$ is not identified without further restrictions since one can always post-multiply $d(L)$ and $c(L)$ by some $q\times q$ polynomial matrix $m(L)$ such that it "cancels out" $k(L)=d(L)c(L)^{-1}=[d(L)m(L)][c(L)m(L)]^{-1}=\bar d(L) \bar c(L)^{-1}$. The problem is that the researcher cannot distinguish between $d(L)c(L)^{-1}$ and $\bar d(L) \bar c(L)^{-1}$ from the first and second moments of the data, and therefore conclusions drawn from the structural IRF $k(z)H$ are meaningless.

Our insight is that $k(L)$ can be identified, that is, the set of matrices $m(L)$ can be narrowed down to $I_q$, using the identification restrictions that are standard in the literature dealing with the identification of the vector autoregressive moving average (VARMA) models.
In this model class, the IRF is given as $k(L)=a(L)^{-1}b(L)$ for some AR and MA lag polynomials $a(L)$ and $b(L)$ of suitable dimensions, and here $a(L)$ and $b(L)$ can be pre-multiplied by some lag polynomial $m(L)$ to obtain an observationally equivalent IRF: $k(L)=a(L)^{-1}b(L)=[m(L)a(L)]^{-1}[m(L)b(L)]=\bar a(L)^{-1}\bar b(L)$.
One popular identification approach for the VARMA model is to use the canonical echelon form parametrization, which involves zero and unity restrictions in $a(L)$ and $b(L)$.
By noting that the identification restrictions for the IRF in right matrix fraction description (RMFD, for short) model, i.e. $k(L)=d(L)c(L)^{-1}$, are equivalent to those for the VARMA model after transposing, the derivation is quite straightforward using the existing results for the VARMA model (for details, see [Appendix A](https://arxiv.org/pdf/2202.00310.pdf#section*.2)).

The structure of the RMFD model in echelon form is quite complicated, and while the functions of this package `rmfd4dfm` code these restrictions without the need for the user to trouble herself with the implementation, one might still wonder what is the point of going through through the painstaking process of deriving and coding the restrictions in the first place, as there are alternatives in the literature?
To make the point, let us introduce a popular alternative used in the literature and compare it with our approach.
One way to deal with the identification and estimation of the DFM presented above is to stack the dynamic factors into a $r=q(s+1)$-dimensional vector $z_t = \left(z_t^{*'}, z_{t-1}^{*'}, \cdots, z_{t-s}^{*'} \right)'$, and write the equation for $x_t$ as $x_t=Dz_t + \xi_t$, where $D=\left(d_0,\cdots,d_s\right)$, which makes the model amenable to the principal components (PC) methods. In the second step, the static factor process is modelled as a VAR process, A(L)z_t = B\varepsilon_t, where $A(L)$ is an $r \times r$ lag polynomial, and $B$ is an $r\times q$ constant matrix.
After the estimation of D and A(L), the IRF $k(L)=DA(L)^{-1}B$ can be constructed straightforwardly.

This alternative using PCs is straightforward from an estimation point of view, but let us point two associated restrictive features. First, note that whenever $s>0$, the minimal number of parameter restrictions needed is $r=q(s+1)$, which is higher than that of needed in our parametrization, i.e. $q$.
Second, we note that the reliable estimation of VAR on $z_t$ can be difficult if the lag order is misspecified, which is due to the singularity of the covariance matrix of the innovation to $z_t$, i.e. $\mathbb E (B\varepsilon_t \varepsilon_t'B')=B\Sigma_\varepsilon B'$ has rank $q$, which is smaller than $r=(s+1)q$ whenever $s>0$.


## Data


## Replication of the monetary policy example

* The idea of the empirical example
* The functions used in the exercise
* Obtaining the results























